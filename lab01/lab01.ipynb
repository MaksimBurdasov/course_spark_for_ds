{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b393022-d673-42c8-8e5a-450340f31fda",
   "metadata": {},
   "source": [
    "# Лаб1. Расчет рейтингов фильмов – RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6e15c-f8dc-4d8c-b884-bd4a31ba882f",
   "metadata": {},
   "source": [
    "### Импорты и настройка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0d85e8-436a-493b-9785-689eb24854bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark-3.4.3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c6482a-596c-4abf-b3d7-3ca6d56250f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://repos.spark-packages.org/ added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /data/home/maksim.burdasov/.ivy2/cache\n",
      "The jars for the packages stored in: /data/home/maksim.burdasov/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0261ab85-6405-4a76-844d-36cc63b76dbf;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.4.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.3.2 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.6 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 469ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.3.2 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.4.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.3 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.6 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0261ab85-6405-4a76-844d-36cc63b76dbf\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/9ms)\n",
      "25/03/16 12:29:30 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/16 12:29:32 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.4.3.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.4.3.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.kafka_kafka-clients-3.3.2.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.5.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.slf4j_slf4j-api-2.0.6.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar added multiple times to distributed cache.\n",
      "25/03/16 12:29:37 WARN yarn.Client: Same path resource file:///data/home/maksim.burdasov/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar added multiple times to distributed cache.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import functions as F\n",
    "# from pyspark.sql.types import *\n",
    "# from pyspark import Row\n",
    "\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(conf=conf)\n",
    "    .appName('max_burdasov_lab1')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bb5eb-d211-4ca6-8776-2da2aa4a5bf2",
   "metadata": {},
   "source": [
    "### Загрузка и агрегация данных"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d63ebc3-be89-40ce-9524-0c5d63a99101",
   "metadata": {},
   "source": [
    "Описание: https://github.com/newprolab/sber-spark-ds-18/blob/main/labs/lab01.md\n",
    "\n",
    "Задача: По имеющимся данным о рейтингах фильмов (MovieLens: 100 000 рейтингов) посчитать агрегированную статистику по ним.\n",
    "Задание необходимо сделать, используя RDD."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8a1fe88-16bc-42e8-8795-b303e8bf2daf",
   "metadata": {},
   "source": [
    "Описание нужного файла:\n",
    "u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.\n",
    "              Each user has rated at least 20 movies.  Users and items are\n",
    "              numbered consecutively from 1.  The data is randomly\n",
    "              ordered. This is a tab separated list of \n",
    "\t         user id | item id | rating | timestamp. \n",
    "              The time stamps are unix seconds since 1/1/1970 UTC\n",
    "\n",
    "Он загружен на HDFS в /labs/laba01/ml-100k. \n",
    "Файл u.data содержит все оценки, а файл u.item — список всех фильмов.\n",
    "\n",
    "Полный путь: /labs/laba01/ml-100k/u.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1a3dad4-cb07-4a0c-8be9-51e40e2c38b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Загрузка данных из HDFS, файл /labs/laba01/ml-100k/u.data\n",
    "rdd = sc.textFile('/labs/laba01/ml-100k/u.data')\n",
    "\n",
    "# Подсчет количества всех оценок\n",
    "all_agg_ratings_lst = (\n",
    "    rdd\n",
    "    .map(lambda row: (row.split('\\t')[2], 1))\n",
    "    .reduceByKey(lambda res, next_val: res + next_val)\n",
    "    .take(5)\n",
    ")\n",
    "\n",
    "# Подсчет количества оценок для фильма с заданным ID\n",
    "target_film_id = '22'\n",
    "trg_agg_ratings_lst = (\n",
    "    rdd\n",
    "    .filter(lambda row: row.split('\\t')[1] == target_film_id)\n",
    "    .map(lambda row: (row.split('\\t')[2], 1))\n",
    "    .reduceByKey(lambda res, next_val: res + next_val)\n",
    "    .take(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a00ec-d550-410c-b85c-7b2e8631ba54",
   "metadata": {},
   "source": [
    "### Форматирование и сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c60ba2df-b0fc-41ae-8ac8-d6666d1054b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортировка по первому элементу (!порядок лексикографический)\n",
    "all_agg_ratings_lst.sort()\n",
    "trg_agg_ratings_lst.sort()\n",
    "\n",
    "# Отформатированный результат\n",
    "out_dict = {\n",
    "   \"hist_film\": [cnt for _, cnt in trg_agg_ratings_lst],\n",
    "   \"hist_all\": [cnt for _, cnt in all_agg_ratings_lst]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a956945e-dcd8-4c8e-9622-63dae9d3e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist_film': [5, 14, 46, 98, 134],\n",
       " 'hist_all': [6110, 11370, 27145, 34174, 21201]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7543ba53-df98-4d79-b016-fa5f5e1116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение результата\n",
    "out_file_path = '/data/home/maksim.burdasov/lab01.json'\n",
    "\n",
    "with open(out_file_path, 'w', encoding='utf8') as f:\n",
    "    json.dump(out_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07406c48-e1d1-43d0-b082-d64799ea7d05",
   "metadata": {},
   "source": [
    "### Завершение контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e4f99e9-937b-4def-8df7-ff447a4bed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
