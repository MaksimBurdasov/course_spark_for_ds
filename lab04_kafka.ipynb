{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32753f75-1baf-466c-8ee1-1d68684220c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark-3.4.3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a52622-404b-4c1c-b29a-19bfd6aa9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c68f1dc-798c-475e-bc32-360f050d02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e45acfd-59cb-4630-9df3-b5ad3afef419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "298164fe-5315-4720-8574-29373e0aa2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"yarn\")\n",
    "    .appName('maxb_lab04_kafka')\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.3\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb49e22-e170-44c9-8e06-7946904886f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all_streams():\n",
    "    \"\"\"Остановить все запущенные стримы.\"\"\"\n",
    "    streams = spark.streams.active\n",
    "    if streams:\n",
    "        for s in streams:\n",
    "            desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "            s.stop()\n",
    "            print(f\"Остановлен стрим: {desc}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543de11f-ac24-4892-9a8b-26254fe4d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kafka(data, topic=\"maksim.burdasov\"):\n",
    "    \"\"\"Записать данные в топик.\"\"\"\n",
    "    # Параметры записи\n",
    "    write_kafka_params = {\n",
    "       \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "       \"topic\": topic\n",
    "    }\n",
    "\n",
    "    # Преобразование данных в JSON\n",
    "    kafka_doc = F.to_json(F.struct(F.col('*')))\n",
    "\n",
    "    # Запись\n",
    "    data.select(\n",
    "        kafka_doc.alias('value')\n",
    "    ).withColumn(\n",
    "        'topic',\n",
    "        F.lit(topic)\n",
    "    ).write.format('kafka').options(**write_kafka_params).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584889b-3ee2-42e9-b7c5-c3fd58f685e7",
   "metadata": {},
   "source": [
    "### Загрузка обученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86db9b8b-f7ee-49f4-972d-22b19eca3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e2c0f8-6628-44a7-b9e4-988510631a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_folder = \"hdfs://spark-master-1.newprolab.com:8020/user/maksim.burdasov/\"\n",
    "\n",
    "gender_model_nm = \"lab04_model_gender_rf_v2\"\n",
    "age_model_nm = \"lab04_model_age_rf_v2\"\n",
    "\n",
    "# Загрузка моделей\n",
    "gender_model = RandomForestClassificationModel.load(my_folder + gender_model_nm)\n",
    "age_model = RandomForestClassificationModel.load(my_folder + age_model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8d11f-adf1-4cee-ab83-5f972786d58a",
   "metadata": {},
   "source": [
    "### Чтение из Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69fa8046-9b63-4e6a-a955-bd8e25ce0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_maksim.burdasov\",\n",
    "    # \"startingOffsets\": \"latest\",  # в батчевом режиме закоментить\n",
    "    # \"maxOffsetsPerTrigger\": \"25000\",\n",
    "    \"failOnDataLoss\": \"False\"\n",
    "}\n",
    "\n",
    "# Подключение к топику\n",
    "kafka_sdf = spark.read.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b6d520-9d8b-4956-9ffa-545bbdc0f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:54:01 WARN admin.AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kafka_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dc4fb27-3a3d-479c-94e0-1bacd1d71b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Парсинг JSON\n",
    "\n",
    "# Схема строки логов\n",
    "log_schema = StructType([\n",
    "    StructField('uid', StringType()),\n",
    "    StructField('visits', StringType())\n",
    "])\n",
    "\n",
    "parsed_sdf = kafka_sdf.select(\n",
    "    F.from_json(\n",
    "        F.col('value').cast('string'), \n",
    "        log_schema\n",
    "    ).alias('user_json')\n",
    ")\n",
    "\n",
    "parsed_sdf = parsed_sdf.withColumn('uid', F.col('user_json.uid'))\n",
    "parsed_sdf = parsed_sdf.withColumn('visits', F.col('user_json.visits'))\n",
    "\n",
    "# Схема содержимого поля visits\n",
    "visits_schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField('url', StringType()),\n",
    "        StructField('timestamp', StringType())\n",
    "    ])\n",
    ")\n",
    "\n",
    "parsed_sdf = parsed_sdf.select(\n",
    "    'uid',\n",
    "    F.from_json(\n",
    "        F.col('visits').cast('string'), \n",
    "        visits_schema\n",
    "    ).alias('visits_json')\n",
    ")\n",
    "\n",
    "parsed_sdf = parsed_sdf.withColumn('urls', F.col('visits_json.url'))\n",
    "parsed_sdf = parsed_sdf.withColumn('timestamps', F.col('visits_json.timestamp'))\n",
    "\n",
    "df = parsed_sdf.select('uid', 'urls', 'timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4159fc46-192a-4aa5-951e-8fe5cb7c6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 22:54:05 WARN admin.AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " uid        | bd7a30e1-a25d-4cb... \n",
      " urls       | [http://www.inter... \n",
      " timestamps | [1419775945781, 1... \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.cache()\n",
    "df.show(1, vertical=True, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc91cd3-4557-43ab-a6df-813ebb1b4416",
   "metadata": {},
   "source": [
    "### Подготовка данных для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35c1160c-2fd7-4a4d-a4b8-e1c343e43adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Колонка с количеством посещенных сайтов\n",
    "df = df.withColumn('urls_cnt', F.size('urls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81ecd93e-4e4f-4879-ae12-557fd2dc47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n",
      "|                 uid|urls_cnt|      tfidf_features|\n",
      "+--------------------+--------+--------------------+\n",
      "|bd7a30e1-a25d-4cb...|    2000|(1024,[0,1,2,3,4,...|\n",
      "+--------------------+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Пайплайн векторизации списка URL\n",
    "\n",
    "# Объединение URL в одну строку\n",
    "df = df.withColumn('urls', F.concat_ws(\" \", 'urls'))\n",
    "\n",
    "# Получение колонки токенов из URL\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"urls\",\n",
    "    outputCol=\"tokens_raw\",\n",
    "    pattern=r\"\\b[\\w]{2,}\\b\",\n",
    "    gaps=False,  # pattern используется для поиска токенов\n",
    "    toLowercase=True\n",
    ")\n",
    "\n",
    "custom_stopwords = [\n",
    "    # Общие служебные слова URL\n",
    "    'http', 'https', 'www', 'com', 'ru', 'net', 'org', 'html', 'php', 'asp', 'aspx', 'jsp',\n",
    "    'utm', 'referrer', 'ref', 'source', 'click', 'id', 'page', 'index', 'feed', 'menu',\n",
    "    'api', 'track', 'trackid', 'session', 'sid', 'token', 'auth', 'access', 'key', 'lang',\n",
    "    'language', 'query', 'search', 'rpt', 'clid', 'clid', 'utm_campaign', 'utm_medium', 'utm_source',\n",
    "    'utm_content', 'utm_term', 'fbclid', 'gclid', 'mc_cid', 'mc_eid',\n",
    "\n",
    "    # Частые параметры и служебные слова\n",
    "    'page', 'view', 'item', 'category', 'product', 'offer', 'promo', 'click', 'redirect',\n",
    "    'index', 'default', 'main',\n",
    "\n",
    "    # Общие слова, малоинформативные для кластеризации\n",
    "    'id', 'type', 'action', 'mode', 'ref', 'referrer', 'sessionid', 'userid', 'user',\n",
    "\n",
    "    # Распространённые сокращения и слова из URL\n",
    "    'www1', 'www2', 'www3', 'mobile', 'm', 'amp', 'cdn', 'static', 'cache',\n",
    "\n",
    "    # Часто встречающиеся короткие слова\n",
    "    'to', 'in', 'on', 'at', 'by', 'of', 'and', 'or', 'for', 'with', 'from'\n",
    "]\n",
    "\n",
    "# Удаление неинформативных слов\n",
    "custom_stopwords = StopWordsRemover.loadDefaultStopWords(\"english\") + custom_stopwords\n",
    "stopwords_remover = StopWordsRemover(\n",
    "    inputCol=\"tokens_raw\",\n",
    "    outputCol=\"tokens\",\n",
    "    stopWords=custom_stopwords\n",
    ")\n",
    "\n",
    "# Расчет TF\n",
    "tf_vectorizer = HashingTF(numFeatures=1024, inputCol=\"tokens\", outputCol=\"tf_features\")\n",
    "\n",
    "# Расчет IDF\n",
    "idf_counter = IDF(inputCol='tf_features', outputCol='tfidf_features')\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, tf_vectorizer, idf_counter])\n",
    "url_ftrs_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Датафрейм с таргетами и фичами по спискам URL\n",
    "url_ftrs_df = (\n",
    "    url_ftrs_df\n",
    "    .select(\n",
    "        # Идентификатор\n",
    "        'uid', \n",
    "        # Колонки фичей\n",
    "        'urls_cnt', \n",
    "        'tfidf_features'\n",
    "    )\n",
    ")\n",
    "\n",
    "url_ftrs_df = url_ftrs_df.cache()\n",
    "url_ftrs_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd98b0db-fb61-4de1-9cde-b6a75f6ab6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " uid              | 7302e78a-ec04-47e... \n",
      " mean_hour        | 16.083333333333332   \n",
      " median_hour      | 16.0                 \n",
      " avg_urls_per_day | 22.90909090909091    \n",
      " night_pct        | 0.3968253968253968   \n",
      " morning_pct      | 18.5515873015873     \n",
      " afternoon_pct    | 41.964285714285715   \n",
      " evening_pct      | 39.08730158730159    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Подготовка фичей из отметок времени\n",
    "\n",
    "# Разворачиваем списки временных отметок\n",
    "df_exploded = df.select('uid', F.explode(F.col('timestamps')).alias('ts')).orderBy('uid', F.col('ts').asc())\n",
    "\n",
    "# Получение дат\n",
    "df_exploded = df_exploded.withColumn(\"ts\", F.from_unixtime(F.col(\"ts\") / 1000))\n",
    "\n",
    "# Отдельные колонки для агрегат\n",
    "df_exploded = df_exploded.withColumn(\"date\", F.to_date(\"ts\"))\n",
    "df_exploded = df_exploded.withColumn(\"hour\", F.hour(\"ts\"))\n",
    "\n",
    "# Флаги захода на сайты по четвертям дня\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"night_flg\", \n",
    "    F.when((df_exploded.hour >= 0) & (df_exploded.hour <= 5), F.lit(1)).otherwise(0)\n",
    ")\n",
    "\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"morning_flg\", \n",
    "    F.when((df_exploded.hour >= 6) & (df_exploded.hour <= 11), F.lit(1)).otherwise(0)\n",
    ")\n",
    "\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"afternoon_flg\", \n",
    "    F.when((df_exploded.hour >= 12) & (df_exploded.hour <= 17), F.lit(1)).otherwise(0)\n",
    ")\n",
    "\n",
    "df_exploded = df_exploded.withColumn(\n",
    "    \"evening_flg\", \n",
    "    F.when((df_exploded.hour >= 18) & (df_exploded.hour <= 23), F.lit(1)).otherwise(0)\n",
    ")\n",
    "\n",
    "# df_exploded.show(30)\n",
    "\n",
    "# Группировка\n",
    "time_ftrs_df = df_exploded.groupBy(\"uid\").agg(\n",
    "    F.mean(F.col('hour')).alias('mean_hour'),\n",
    "    F.median(F.col('hour')).alias('median_hour'),\n",
    "    (F.count('*') / F.count_distinct(F.col('date'))).alias('avg_urls_per_day'),\n",
    "    (F.sum(F.col('night_flg')) * 100.0 / F.count('*')).alias('night_pct'),\n",
    "    (F.sum(F.col('morning_flg')) * 100.0 / F.count('*')).alias('morning_pct'),\n",
    "    (F.sum(F.col('afternoon_flg')) * 100.0 / F.count('*')).alias('afternoon_pct'),\n",
    "    (F.sum(F.col('evening_flg')) * 100.0 / F.count('*')).alias('evening_pct'),\n",
    ")\n",
    "\n",
    "# Показываем результат\n",
    "time_ftrs_df = time_ftrs_df.cache()\n",
    "time_ftrs_df.show(1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e231132-6c77-4ccb-bc25-19a8f87e79f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " uid              | 0108d217-e476-493... \n",
      " urls_cnt         | 3                    \n",
      " tfidf_features   | (1024,[99,124,215... \n",
      " mean_hour        | 12.0                 \n",
      " median_hour      | 12.0                 \n",
      " avg_urls_per_day | 3.0                  \n",
      " night_pct        | 0.0                  \n",
      " morning_pct      | 0.0                  \n",
      " afternoon_pct    | 100.0                \n",
      " evening_pct      | 0.0                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Получение датасета со всеми фичами\n",
    "union_df = url_ftrs_df.join(time_ftrs_df, how='left', on='uid')\n",
    "\n",
    "union_df = union_df.cache()\n",
    "union_df.show(1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76885c5d-31c7-4330-bef9-0698fe63f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------\n",
      " uid              | 0108d217-e476-493... \n",
      " urls_cnt         | 3                    \n",
      " tfidf_features   | (1024,[99,124,215... \n",
      " mean_hour        | 12.0                 \n",
      " median_hour      | 12.0                 \n",
      " avg_urls_per_day | 3.0                  \n",
      " night_pct        | 0.0                  \n",
      " morning_pct      | 0.0                  \n",
      " afternoon_pct    | 100.0                \n",
      " evening_pct      | 0.0                  \n",
      " features         | (1032,[0,100,125,... \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Помещение всех признаков в один вектор\n",
    "\n",
    "feature_cols = [\n",
    "    \"urls_cnt\",\n",
    "    \"tfidf_features\",\n",
    "    \"mean_hour\",\n",
    "    \"median_hour\",\n",
    "    \"avg_urls_per_day\",\n",
    "    \"night_pct\",\n",
    "    \"morning_pct\",\n",
    "    \"afternoon_pct\",\n",
    "    \"evening_pct\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "final_df = assembler.transform(union_df)\n",
    "\n",
    "final_df.show(1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431ddd18-bb1c-4067-b8d6-4d802200ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 uid|            features|\n",
      "+--------------------+--------------------+\n",
      "|0108d217-e476-493...|(1032,[0,100,125,...|\n",
      "|0192cc54-559c-4c8...|(1032,[0,33,34,55...|\n",
      "|019acd5e-be9a-4cd...|(1032,[0,2,10,25,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer_df = final_df.select('uid', 'features')\n",
    "\n",
    "infer_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078e530-e8e6-4f11-96b8-1828873a87c9",
   "metadata": {},
   "source": [
    "### Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a65e1c-1076-43c4-b53f-fceab6b9d8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                 uid|            features|gender|\n",
      "+--------------------+--------------------+------+\n",
      "|0108d217-e476-493...|(1032,[0,100,125,...|     F|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_preds = gender_model.transform(infer_df)\n",
    "gen_preds = gen_preds.select(\n",
    "    'uid',\n",
    "    'features',\n",
    "    F.when(F.col('prediction') == 0, 'F').otherwise('M').alias('gender')\n",
    ")\n",
    "\n",
    "gen_preds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5339bd9-a0af-45b4-b145-eb15ce2b5e19",
   "metadata": {},
   "source": [
    "Словарь маппинга возрастов\n",
    "mapping_dict = {\n",
    "    0: '18-24', \n",
    "    1: '25-34', \n",
    "    2: '35-44', \n",
    "    3: '45-54', \n",
    "    4: '>=55'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8bb5050-c361-49b2-ab8d-7563368aa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_preds = age_model.transform(gen_preds)\n",
    "\n",
    "preds = age_preds.select(\n",
    "    'uid',\n",
    "    'gender',\n",
    "    F.col('prediction').alias('age')\n",
    ")\n",
    "\n",
    "preds = preds.withColumn(\n",
    "    'age',\n",
    "    F.when(F.col('age') == 0, '18-24')\n",
    "    .when(F.col('age') == 1, '25-34')\n",
    "    .when(F.col('age') == 2, '35-44')\n",
    "    .when(F.col('age') == 3, '45-54')\n",
    "    .when(F.col('age') == 4, '>=55')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50888551-25eb-4708-84e9-60b7f2d0be41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------+-----+\n",
      "|uid                                 |gender|age  |\n",
      "+------------------------------------+------+-----+\n",
      "|0108d217-e476-493d-8c81-a9744f12451a|F     |25-34|\n",
      "+------------------------------------+------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e2cc8-c948-4ac2-9478-afae2a4b8a42",
   "metadata": {},
   "source": [
    "### Запись в Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da61c023-7253-44a7-9b4d-9822fd3eda10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_kafka(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d6667-fe82-4a94-bcbc-5b6943cf9266",
   "metadata": {},
   "source": [
    "### Остановка контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7dc4090-a16e-4840-bc1c-7e93a6ea8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
